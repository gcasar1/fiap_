{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcasar1/fiap_/blob/main/deteccao_liveness_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85dgi9An6h2C"
      },
      "source": [
        "# MBA FIAP Inteligência Artificial & Machine Learning\n",
        "\n",
        "## Visão Computacional: Análise de Imagens Médicas\n",
        "\n",
        "> Atenção: este notebook foi desenhado para funcionar no **Google Collab**.\n",
        "\n",
        "\n",
        "## 1. Introdução\n",
        "\n",
        "Uma determinada fintech focada em consumidores finais pessoa física constataou um grande número de fraudes em transações bancárias.\n",
        "\n",
        "O setor de fraudes apontou que existem clientes que se queixaram de não contratar serviços específicos, como o crédito pessoal, e após isso transferir para outras contas desconhecidas.\n",
        "\n",
        "Após análises pelas equipes de segurança, os protocolos de utilização da senha foram realizados em conformidade, ou seja, cada cliente autenticou com sua própria senha de maneira regular.\n",
        "\n",
        "Em função disso, o banco precisa arcar com reembolsos e medidas de contenção para evitar processos judiciais, pois os clientes alegam terem sido invadidos por hackers ou algo parecido.\n",
        "\n",
        "Uma das formas de solucionar ou minimizar este problema é com a utilização de outras formas de autenticação, sobretudo em operações críticas, como a obtenção de crédito pessoal.\n",
        "\n",
        "Desta forma podemos implementar uma verificação de identidade com prova de vida (liveness), que utilize uma verificação e identificação facial.\n",
        "\n",
        "Caso o cliente não seja autenticado, ele será atendido por uma esteira dedicada e as evidências da não identificação serão encaminhadas para a área de IA para validação dos parâmetros e limiares para aperfeiçoamento do modelo.\n",
        "\n",
        "Será necessário construir:\n",
        "\n",
        "* Detector de faces\n",
        "* Identificação de faces (podendo ser um comparador entre um rosto de documento e outra da prova de vida)\n",
        "* Detecção de vivacidade (liveness) para evitar que um fraudador utilize uma foto estática.\n",
        "\n",
        "\n",
        ">Formas alternativas de prover a identificação e prova de vivacidade, além destas que foram solicitadas poderão ser submetidas.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/michelpf/fiap-ml-visao-computacional-detector-liveness/blob/master/notebook/imagens/liveness.jpg?raw=1\">\n",
        "</p>\n",
        "\n",
        "Imagem retirada do [Grunge](https://www.grunge.com/192826/company-testing-robocop-facial-recognition-software-with-us-police/).\n",
        "\n",
        "## 2. Instruções\n",
        "\n",
        "Este projeto final tem como objetivo explorar os conhecimentos adquiridos nas aulas práticas.\n",
        "\n",
        "Iremos constuir uma forma de validar se uma determinada imagem foi ou não adulterada e se trata de uma produção fraudade.\n",
        "\n",
        "Existem diversas formas de validar a vivacidade, e neste sentido conto com a criatividade de vocês dado que já dominam encontrar uma face numa imagem, aplicar marcos faciais e até mesmo construir uma rede neural convulacional.\n",
        "\n",
        "A abordagem mais simples é pela construção de uma rede neural com imagens de fotos de rostos de outras fotos e fotos de rostos sem modificações. Tal classificador deverá classificar se dada imagem possui vivacidade ou não com uma pontuação de probabilidade.\n",
        "\n",
        "Referências que abordam o tema para servir de inspiração:\n",
        "\n",
        "1. [PyImageSearch](https://pyimagesearch.com/2019/03/11/liveness-detection-with-opencv/), Liveness detection with OpenCV;\n",
        "2. [Kickertech](https://kickertech.com/face-liveness-detection-via-opencv-and-tensorflow/), Liveness detection via OpenCV and Tensorflow.\n",
        "3. [Towards Data Science](https://towardsdatascience.com/real-time-face-liveness-detection-with-python-keras-and-opencv-c35dc70dafd3?gi=24f8e1b740f9), Real-time face liveness detection with Python, Keras and OpenCV.\n",
        "\n",
        "Este projeto poderá ser feita por grupos de até 4 pessoas.\n",
        "Caso este projeto seja substitutivo, deverá ser realizado por apenas uma pessoa.\n",
        "\n",
        "| Nome dos Integrantes                       | RM         | Turma   |\n",
        "| :----------------------------------------- | :--------- | :-----: |\n",
        "| Gabriela Casari                            | RM 351352  | 5DTSR   |\n",
        "| Jeferson Souto                             | RM 352350  | 5DTSR   |\n",
        "| Pedro Henrique Decezaro Vicensi            | RM 351482  | 5DTSR   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DBTFR1x6h2E"
      },
      "source": [
        "## 3. Abordagem e organização da solução do problema (2 pontos)\n",
        "\n",
        "Como o grupo pretende deteccar a prova de vivacidade de uma determinada imagem? Quais os passos e os building blocks deste processo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLeq3PET6h2E"
      },
      "source": [
        "**Resposta**:\n",
        "Para detectar a prova de vivacidade em fotos, incluindo tentativas de fraude como o uso de máscaras, o grupo usará o Amazon Rekognition Custom Labels. O modelo será treinado para identificar características sutis que distinguem uma face real de uma falsa, como diferenças de textura e profundidade. O processo envolve a análise de fotos enviadas pelos usuários para detectar anomalias típicas de máscaras ou fotos planas. O Amazon Rekognition facilita a criação de modelos personalizados que podem identificar essas nuances, proporcionando uma camada adicional de segurança em sistemas de autenticação facial. Essa abordagem permite uma detecção rápida e precisa, garantindo que apenas faces reais sejam reconhecidas como válidas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4M2W5uH6h2E"
      },
      "source": [
        "## 4 Desenvolvimento da solução (5,5 pontos)\n",
        "\n",
        "Detalhe o passo-a-passo do algoritmo de deteção de vivacidade.\n",
        "Se optar pela construção e treinamento de um modelo de redes neurais convulucionais, apresente a arquitetura, prepare os dados de treinamento, realize o treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "554zeM2e6h2E"
      },
      "source": [
        "### 4.1 Organização de dados para treinamento de modelo de liveness (2 pontos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec2qK0UJiUxt",
        "outputId": "d7d09ef7-ef29-4e49-d24d-00dab359c652"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.34.152-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting botocore<1.35.0,>=1.34.152 (from boto3)\n",
            "  Downloading botocore-1.34.152-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.152->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.152->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.152->boto3) (1.16.0)\n",
            "Downloading boto3-1.34.152-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.34.152-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.34.152 botocore-1.34.152 jmespath-1.0.1 s3transfer-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install awscli"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5WtoYd3lLkt",
        "outputId": "f32e4667-d18d-49c5-ee06-ef0db06107a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.33.34-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: botocore==1.34.152 in /usr/local/lib/python3.10/dist-packages (from awscli) (1.34.152)\n",
            "Collecting docutils<0.17,>=0.10 (from awscli)\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.10.2)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (6.0.1)\n",
            "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.152->awscli) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.152->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.152->awscli) (2.0.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.34.152->awscli) (1.16.0)\n",
            "Downloading awscli-1.33.34-py3-none-any.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: rsa, docutils, colorama, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "Successfully installed awscli-1.33.34 colorama-0.4.6 docutils-0.16 rsa-4.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import json\n",
        "import requests\n",
        "import os"
      ],
      "metadata": {
        "id": "I8Ge6V4NBNPc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACCESS_KEY = 'xxx'\n",
        "ACCESS_SECRET = 'xxx'\n",
        "REGION = \"us-east-1\"\n"
      ],
      "metadata": {
        "id": "fydsWXu5BqFF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_model(project_arn, model_arn, version_name, min_inference_units):\n",
        "\n",
        "    client=boto3.client('rekognition')\n",
        "\n",
        "    try:\n",
        "        print('Starting model: ' + model_arn)\n",
        "        response=client.start_project_version(ProjectVersionArn=model_arn, MinInferenceUnits=min_inference_units)\n",
        "        project_version_running_waiter = client.get_waiter('project_version_running')\n",
        "        project_version_running_waiter.wait(ProjectArn=project_arn, VersionNames=[version_name])\n",
        "        describe_response=client.describe_project_versions(ProjectArn=project_arn,\n",
        "            VersionNames=[version_name])\n",
        "        for model in describe_response['ProjectVersionDescriptions']:\n",
        "            print(\"Status: \" + model['Status'])\n",
        "            print(\"Message: \" + model['StatusMessage'])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    print('Done...')\n",
        "\n",
        "def main():\n",
        "    project_arn='arn:aws:rekognition:us-east-1:011528301996:project/Faces/1722552711471'\n",
        "    model_arn='arn:aws:rekognition:us-east-1:011528301996:project/Faces/version/Faces.2024-08-01T19.59.45/1722553185343'\n",
        "    min_inference_units=1\n",
        "    version_name='Faces.2024-08-01T19.59.45'\n",
        "    start_model(project_arn, model_arn, version_name, min_inference_units)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkDKyNwAByOs",
        "outputId": "37464bd6-12ba-412e-e613-0b8f3bc457bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model: arn:aws:rekognition:us-east-1:011528301996:project/Faces/version/Faces.2024-08-01T19.59.45/1722553185343\n",
            "Status: RUNNING\n",
            "Message: The model is running.\n",
            "Done...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mA8zL_L6h2F"
      },
      "source": [
        "### 4.2 Treinamento de modelo de liveness (1,5 pontos)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O treinamento foi feito pela Amazon Rekognition Custom."
      ],
      "metadata": {
        "id": "vqL7qkXyfSfT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLWl20GG6h2G"
      },
      "source": [
        "### 4.3 Métricas de desempenho do modelo (2 pontos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json\n",
        "\n",
        "def get_s3_object(bucket, key):\n",
        "    s3 = boto3.client('s3')\n",
        "    try:\n",
        "        response = s3.get_object(Bucket=bucket, Key=key)\n",
        "        content = response['Body'].read().decode('utf-8')\n",
        "        return json.loads(content)\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching S3 object:\", e)\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    bucket = 'custom-labels-console-us-east-1-xxx'\n",
        "    summary_key = 'evaluation/arn:aws:rekognition:us-east-1:011528301996:project/Faces/1722552711471/EvaluationResultSummary-Faces-Faces.2024-08-01T19.59.45.json'\n",
        "\n",
        "    summary = get_s3_object(bucket, summary_key)\n",
        "\n",
        "    if summary:\n",
        "        print(\"Evaluation Summary:\")\n",
        "        print(json.dumps(summary, indent=4))\n",
        "        if 'Summary' in summary:\n",
        "            precision = summary.get('Precision', 'Not Available')\n",
        "            recall = summary.get('Recall', 'Not Available')\n",
        "            print(f\"Precision: {precision}\")\n",
        "            print(f\"Recall: {recall}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm5dNL4nRqq4",
        "outputId": "23efda7f-ccb9-4dc6-da91-ace8ae289f0f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Summary:\n",
            "{\n",
            "    \"AggregatedEvaluationResults\": {\n",
            "        \"ConfusionMatrix\": [\n",
            "            {\n",
            "                \"GroundTruthLabel\": \"Real\",\n",
            "                \"PredictedLabel\": \"Real\",\n",
            "                \"Value\": 0.6666666666666666\n",
            "            },\n",
            "            {\n",
            "                \"GroundTruthLabel\": \"Real\",\n",
            "                \"PredictedLabel\": \"Fake\",\n",
            "                \"Value\": 0.3333333333333333\n",
            "            },\n",
            "            {\n",
            "                \"GroundTruthLabel\": \"Fake\",\n",
            "                \"PredictedLabel\": \"Real\",\n",
            "                \"Value\": 0.3333333333333333\n",
            "            },\n",
            "            {\n",
            "                \"GroundTruthLabel\": \"Fake\",\n",
            "                \"PredictedLabel\": \"Fake\",\n",
            "                \"Value\": 0.6666666666666666\n",
            "            }\n",
            "        ],\n",
            "        \"F1Score\": 0.8571428571428571,\n",
            "        \"Precision\": 0.75,\n",
            "        \"Recall\": 1.0\n",
            "    },\n",
            "    \"EvaluationDetails\": {\n",
            "        \"EvaluationEndTimestamp\": \"2024-08-01T23:11:25.388135\",\n",
            "        \"Labels\": [\n",
            "            \"Real\",\n",
            "            \"Fake\"\n",
            "        ],\n",
            "        \"NumberOfTestingImages\": 6,\n",
            "        \"NumberOfTrainingImages\": 18,\n",
            "        \"ProjectVersionArn\": \"arn:aws:rekognition:us-east-1:011528301996:project/Faces/version/Faces.2024-08-01T19.59.45/1722553185343\"\n",
            "    },\n",
            "    \"LabelEvaluationResults\": [\n",
            "        {\n",
            "            \"Label\": \"Real\",\n",
            "            \"Metrics\": {\n",
            "                \"F1Score\": 0.8571428571428571,\n",
            "                \"Precision\": 0.75,\n",
            "                \"Recall\": 1.0,\n",
            "                \"Threshold\": 0.15468\n",
            "            },\n",
            "            \"NumberOfTestingImages\": 3\n",
            "        },\n",
            "        {\n",
            "            \"Label\": \"Fake\",\n",
            "            \"Metrics\": {\n",
            "                \"F1Score\": 0.8571428571428571,\n",
            "                \"Precision\": 0.75,\n",
            "                \"Recall\": 1.0,\n",
            "                \"Threshold\": 0.22993\n",
            "            },\n",
            "            \"NumberOfTestingImages\": 3\n",
            "        }\n",
            "    ],\n",
            "    \"Version\": 1\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlRU5cE86h2G"
      },
      "source": [
        "## 5 Teste Fim-a-Fim\n",
        "\n",
        "Simule a operação fim-a-fim, com uma imagem de entrada forjada (foto de foto de um rosto) e outra com uma imagem de rosto, exibindo o resultado da classificação e a pontuação de cada classe."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "def detect_liveness(image_path, model_arn, min_confidence=95):\n",
        "    client = boto3.client('rekognition')\n",
        "    with open(image_path, 'rb') as image_file:\n",
        "        image_bytes = image_file.read()\n",
        "\n",
        "    response = client.detect_custom_labels(\n",
        "        Image={'Bytes': image_bytes},\n",
        "        ProjectVersionArn=model_arn,\n",
        "        MinConfidence=min_confidence\n",
        "    )\n",
        "\n",
        "    return response['CustomLabels']\n",
        "\n",
        "def main():\n",
        "    model_arn = 'arn:aws:rekognition:us-east-1:011528301996:project/Faces/version/Faces.2024-08-01T19.59.45/1722553185343'\n",
        "\n",
        "    fake_image_path = 'fake_1.jpg'\n",
        "    real_image_path = 'real_1.jpeg'\n",
        "\n",
        "    # Detecta vivacidade na imagem forjada\n",
        "    fake_labels = detect_liveness(fake_image_path, model_arn)\n",
        "    print(\"\\nResultado para a imagem forjada:\")\n",
        "    if fake_labels:\n",
        "        for label in fake_labels:\n",
        "            print(f\"Rótulo: {label['Name']}, Confiança: {label['Confidence']:.2f}\")\n",
        "    else:\n",
        "        print(\"Nenhum rótulo detectado.\")\n",
        "\n",
        "    real_labels = detect_liveness(real_image_path, model_arn)\n",
        "    print(\"\\nResultado para a imagem real:\")\n",
        "    if real_labels:\n",
        "        for label in real_labels:\n",
        "            print(f\"Rótulo: {label['Name']}, Confiança: {label['Confidence']:.2f}\")\n",
        "    else:\n",
        "        print(\"Nenhum rótulo detectado.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpG69gPRcDY2",
        "outputId": "9c29810e-f750-48ad-f624-c56d45115296"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultado para a imagem forjada:\n",
            "Rótulo: Fake, Confiança: 96.14\n",
            "\n",
            "Resultado para a imagem real:\n",
            "Rótulo: Real, Confiança: 95.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jno_Y5N96h2G"
      },
      "source": [
        ">Com a implementação da solução na forma de uma aplicação do [Streamlit](https://www.streamlit.io/) (veja a pata streamlit-app e use o template) vale 1 ponto adicional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBeOX-Bd6h2G"
      },
      "source": [
        "**Pergunta**: Se utilizou o Streamlit, compartilhe a URL do aplicativo publicado:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLI3DeCf6h2G"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzlTnVgr6h2G"
      },
      "source": [
        "## 6 Conclusões (2,5 pontos)\n",
        "\n",
        "**Pergunta**: Dado todo o estudo e pesquisa, quais foram as conclusões sobre a solução, o que funcionou, o que não funcionou e quais os detalhes que observariam numa nova versão e melhorias do processo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1kPQKVL6h2G"
      },
      "source": [
        "**Resposta**:\n",
        "O experimento com Amazon Rekognition Custom Labels demonstrou eficácia em distinguir imagens reais de forjadas, com alta confiança: 96.14% para \"Fake\" e 95.53% para \"Real\". O modelo funcionou bem. Para melhorar, é interessante sempre aumentar a diversidade do dataset de treinamento. Além disso, a integração de detecção de anomalias e ajustes contínuos do modelo pode aprimorar sua robustez e adaptabilidade contra novas fraudes. Assim, o sistema pode se manter eficiente em cenários mais complexos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "733a071da2455ea0e8bdf5409a7097e630ac701195faf55c6e985d77ee3ec176"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}